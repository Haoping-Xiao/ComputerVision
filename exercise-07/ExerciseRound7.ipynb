{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true;\n",
       "function code_toggle() {\n",
       "if (code_show){\n",
       "$('div.input').hide();\n",
       "} else {\n",
       "$('div.input').show();\n",
       "}\n",
       "code_show = !code_show\n",
       "}\n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is used for creating a button that hides/unhides code cells to quickly look only the results.\n",
    "# Works only with Jupyter Notebooks.\n",
    "\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "} else {\n",
    "$('div.input').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "}\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n",
      "Data stored in /coursedata/exercise-07-data\n"
     ]
    }
   ],
   "source": [
    "# Description:\n",
    "#   Exercise7 notebook.\n",
    "#\n",
    "# Copyright (C) 2018 Santiago Cortes, Juha Ylioinas\n",
    "#\n",
    "# This software is distributed under the GNU General Public \n",
    "# Licence (version 2 or later); please refer to the file \n",
    "# Licence.txt, included with the software, for details.\n",
    "\n",
    "# Preparations\n",
    "import numpy as np\n",
    "\n",
    "# Select data directory\n",
    "if os.path.isdir('/coursedata'):\n",
    "    # JupyterHub\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../../../coursedata'):\n",
    "    # Local installation\n",
    "    course_data_dir = '../../../coursedata'\n",
    "else:\n",
    "    # Docker\n",
    "    course_data_dir = '/home/jovyan/work/coursedata/'\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)\n",
    "data_dir = os.path.join(course_data_dir, 'exercise-07-data')\n",
    "print('Data stored in %s' % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-E4850 Computer Vision Exercise Round 7\n",
    "The problems should be solved before the exercise session and solutions returned via\n",
    "MyCourses. <br><br> For this exercise round, upload this notebook(pdf and .ipynb versions) containing your source codes (for Exercise 1) and your answer to the question of Exercise2, and all the answers to the questions of Exercise 3 (VGG practical), see part[1-3].ipynb. Note that it's not necessary to upload part1.ipynb, part2.ipynb or part3.ipynb, because all of the necessary questions related to them are contained in this notebook and you're not expected to do any coding in Exercises 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Comparing  bags-of-words  with  tf-idf  weighting\n",
    "Assume  that  we  have  an  indexed  collection  of  documents  containing  the  five  terms  of the following table where the second row indicates the percentage of documents in which each term appears.<br>\n",
    "\n",
    "| term | cat | dog |mammals | mouse | pet |\n",
    "| --- | :---: | :---: | :---: | :---: | :---: |\n",
    "| **% of documents** | 5 | 20 | 2 | 10 | 60 |\n",
    "\n",
    "Now, given the query $Q=\\{mouse, cat, pet, mammals\\}$, compute the similarity between $Q$ and the following example documents $D1$, $D2$, $D3$, by using the cosine similarity measure and tf-idf weights (i.e. term frequency - inverse document frequency) for the bag-of-words histogram representations of the documents and the query.\n",
    "\n",
    "-  $D1$ = Cat is a pet, dog is a pet, and mouse may be a pet too.\n",
    "-  $D2$ = Cat, dog and mouse are all mammals.\n",
    "-  $D3$ = Cat and dog get along well, but cat may eat a mouse.\n",
    "\n",
    "Ignore other words except the five terms. You may proceed with the following steps:\n",
    "\n",
    "a) Compute and report the inverse document frequency (idf) for each of the five terms. Use the logarithm with base 2. (idf is the logarithm on slide 69 of Lecture 6.)<br>\n",
    "b) Compute the term frequencies for the query and each document. <br>\n",
    "c) Form the tf-idf weighted word occurrence histograms for the query and documents. <br>\n",
    "d) Evaluate the cosine similarity between the query and each document (i.e.\\ normalized scalar product between the weighted occurrence histograms as shown on slide 45).<br> \n",
    "e) Report the relative ranking of the documents. (You should get similarities 0.95, 0.64, and 0.63, but you need to determine which corresponds to which document.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat, dog and mouse are all mammals has similarity 0.9546948111493487\n",
      "Cat and dog get along well, but cat may eat a mouse has similarity 0.643193739330242\n",
      "Cat is a pet, dog is a pet, and mouse may be a pet too has similarity 0.6288846426378089\n"
     ]
    }
   ],
   "source": [
    "## Comparing  bags-of-words  with  tf-idf  weighting\n",
    "##--your-code-starts-here--##\n",
    "#given data\n",
    "df={'cat':0.05,'dog':0.2,'mammals':0.02,'mouse':0.1,'pet':0.6}\n",
    "docs={0:'Cat is a pet, dog is a pet, and mouse may be a pet too',\n",
    "      1:'Cat, dog and mouse are all mammals',\n",
    "      2:'Cat and dog get along well, but cat may eat a mouse',\n",
    "      'Q':'mouse, cat, pet, mammals'}\n",
    "\n",
    "#compute idf\n",
    "idf={}\n",
    "for key in df:\n",
    "    idf[key]=np.log2(1/df[key])\n",
    "\n",
    "tf_idf=[]\n",
    "#vector of documents\n",
    "t=[]\n",
    "#compute tf-idf and vector of documents\n",
    "for doc_key in docs:\n",
    "    tf_doc={'cat':0,'dog':0,'mammals':0,'mouse':0,'pet':0}\n",
    "    #get each word in the sentence\n",
    "    words=docs[doc_key].split(' ')\n",
    "    #number of words\n",
    "    n=len(words)\n",
    "    #count if word in df.keys()\n",
    "    for word in words:\n",
    "        for key in tf_doc:\n",
    "            if key in word.lower():\n",
    "                tf_doc[key]+=1\n",
    "    #summarized\n",
    "    t_doc=[tf_doc[key] for key in tf_doc]\n",
    "    tf_idf_doc=[((value/n)*idf[key]) for key,value in tf_doc.items()]\n",
    "    tf_idf.append(tf_idf_doc)\n",
    "    t.append(t_doc)\n",
    "    \n",
    "tf_idf=np.array(tf_idf)\n",
    "\n",
    "#calculate similarity\n",
    "similarity=np.zeros((3,))\n",
    "for i in range(similarity.shape[0]):\n",
    "    sim=np.sum(tf_idf[i]*tf_idf[-1])/(np.linalg.norm(tf_idf[i])*np.linalg.norm(tf_idf[-1]))\n",
    "    similarity[i]=sim\n",
    "#sort in descending order\n",
    "rank=np.argsort(-1*similarity)\n",
    "for i in range(similarity.shape[0]):\n",
    "    print('{0} has similarity {1}'.format(docs[rank[i]],similarity[rank[i]]))\n",
    "\n",
    "##--your-code-ends-here--##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer for exercise 1\n",
    "As the output shown above, the D2 has the largest similarity 0.95, following by D3(0.64) and D1(0.63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Precision  and  recall\n",
    "There is a database of 10000 images and a user, who is only interested in images which contain a car. It is known that there are 500 such images in the database. An  automatic image retrieval system retrieves 300 car images and 50 other images from the database. Determine and report the precision and recall of the retrieval  system in this particularcase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here:\n",
    "\n",
    "Precision: (300/350)=0.86\n",
    "\n",
    "Recall: (300/500)=0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - VGG practical on object instance recognition\n",
    "See the questions in part[1-3].ipynb and write your answers here.\n",
    "\n",
    "Part1:\n",
    "Stage I.A (two questions)\n",
    "Stage I.B (two questions)\n",
    "Stage I.C (one question)\n",
    "\n",
    "Part2 (one question)\n",
    "\n",
    "Part3:\n",
    "Stage III.A (three questions)\n",
    "Stage III.B (one question)\n",
    "Stage III.C (two questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answers here: \n",
    "\n",
    "### Stage I.A in Part1:\n",
    "1. The reason of change is different illumination and contrast. Because of bad illumination in the second image, the grey values of those extremely dark and light areas will be close and this areas cannot be detected as features. It would be a problem for matching because there are no corresponding features. To aviod this situation, we can use histogram equalization to improve this situation.\n",
    "\n",
    "\n",
    "2. To assign the directionï¼ŒSIFT need to compute histogram of local gradient directions in the patch. If there are multiple peaks in the histogram, then the feature will have different orientation. If there are multiple keypoints in one area, then this situation will appear.\n",
    "\n",
    "### Stage I.B in Part1:\n",
    "1. There might be mulitple close neighbour in another image if the region is small. If we have descriptors over a much larger region, they can help us identify the corresponding SIFT descriptor in another image quickly.\n",
    "\n",
    "2. There are very similar structures in this building. And then the change in lighting results in mismatch. We can use nearest neighbor distance ratio to improve the performance.\n",
    "\n",
    "### Stage I.C in Part1:\n",
    "1. Most remaining mismatches are in the drak region. Therefore, we can check the pixel value, if the grey value close to 0, then remove them.\n",
    "\n",
    "### Part2:\n",
    "1. Firstly, We can use Harris corner detector to get features because it has affine co-variant. Secondly, we can use 3 corresponding points to fit an affine transformation. Thirdly, check SIFT matches using the transformation matrix computed in step2. Lastly, if the results are bad, then go to step 2 to find a better affine transformation matrix again.\n",
    "\n",
    "### Stage III.A in Part3:\n",
    "1. When the size of vocabulary is large, then the number of inliers will increase but it also increases computation difficulty to find inliers.\n",
    "\n",
    "2. Because matching descriptors is extremely quick compared to the time of convertion. If add the time of convertion, then the time of matching descriptors can be ignored.\n",
    "\n",
    "3. We can use vocabulary trees to store words.\n",
    "\n",
    "### Stage III.B in Part3:\n",
    "1. Because its words already stored in vocabulary and this score measures similarity(e.g. consine similarity).\n",
    "\n",
    "### Stage III.C in Part3:\n",
    "1. Because the score now is the number of inliers word. \n",
    "\n",
    "2. Yes. Now the order of result is more accurate.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
